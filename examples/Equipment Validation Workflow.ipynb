{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "twelve-serum",
   "metadata": {},
   "source": [
    "# 1) Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-compromise",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "referenced-closer",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Imports\n",
    "# ----------------------------------------\n",
    "import os\n",
    "\n",
    "from rdflib import Namespace, SH, RDF, BNode\n",
    "from pyshacl import validate\n",
    "\n",
    "from tasty import constants as tc\n",
    "from tasty import graphs as tg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-riding",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "Define the key variables and input information here\n",
    "\n",
    "***Items to Change***\n",
    "- `SHAPE`: this is the name of the SHACL equipment shape against which you would like to validate your sample equipment in the instance data\n",
    "- `SAMPLE`: this is the name of the sample equipment in your instance data\n",
    "- `input_namespace_uri`: this is the namespace uri used for your sample equipment in the instance data\n",
    "- `data_graph_filename`: this is the filename/filepath of the instance data for the data graph\n",
    "- `shapes_graph_filename`: this it the filename/filepath of the SHACL shapes data for the shape graph \n",
    "***Remaining Items*** </br>\n",
    "These items should be okay as is, but can be changed if need be. If you are printing out results, <u>*make sure that the output directory exists in your local file structure*</u>.\n",
    "- `output_directory`: this is the directory where output files will be printed to below\n",
    "- `tasty_main_directory`: this is the absolute path of the main tasty directory. It should just be the parent directory of the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "organized-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# User Defined Variables\n",
    "# ----------------------------------------\n",
    "\n",
    "SHAPE = 'NREL-VAV-Test-Shape'\n",
    "SAMPLE = 'NREL-Equip-Test'\n",
    "input_namespace_uri = 'urn:sample/'\n",
    "\n",
    "data_graph_filename = 'examples/example_data/input/example_data.ttl'\n",
    "shapes_graph_filename = 'examples/example_data/input/example_shapes.ttl'\n",
    "\n",
    "output_directory = os.path.join(os.path.abspath(''), 'examples/example_data/output')\n",
    "tasty_main_directory = os.path.join(os.path.abspath(''), '../')\n",
    "# print(tasty_main_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-singles",
   "metadata": {},
   "source": [
    "# 2) Main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-collar",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "This defines additional variables and helper functions to be used below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "wrong-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Variables and Constants\n",
    "# ----------------------------------------\n",
    "\n",
    "NAMESPACE = Namespace(input_namespace_uri)\n",
    "shape_name = tc.PH_SHAPES_NREL[SHAPE]\n",
    "target_node = NAMESPACE[SAMPLE]\n",
    "\n",
    "# ----------------------------------------\n",
    "# Helper Function Definitions\n",
    "# ----------------------------------------\n",
    "\n",
    "def get_data_graph():\n",
    "    n = tg.get_versioned_graph(tc.HAYSTACK, tc.V3_9_10)\n",
    "    f = os.path.join(tasty_main_directory, data_graph_filename)\n",
    "    n.parse(f, format='turtle')\n",
    "    return n\n",
    "\n",
    "\n",
    "def get_shapes_graph():\n",
    "    g = tg.get_versioned_graph(tc.HAYSTACK, tc.V3_9_10)\n",
    "    f = os.path.join(tasty_main_directory, shapes_graph_filename)\n",
    "    g.parse(f, format='turtle')\n",
    "    return g\n",
    "\n",
    "\n",
    "def print_graph_to_file(g, filename):\n",
    "    output_filename = os.path.join(output_directory, filename + \".ttl\")\n",
    "    g.serialize(output_filename, format='turtle')\n",
    "\n",
    "\n",
    "def print_graph(g):\n",
    "    print(g.serialize(format='turtle').decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-index",
   "metadata": {},
   "source": [
    "## Generate Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-viking",
   "metadata": {},
   "source": [
    "### Create Data, Shapes, and Ontology Graphs \n",
    "Create the data and shapes graph using the helper functions defined above. The data and shapes graphs are generated using rdflib's `parse` function to import the graphs defined in `data_graph_filename` and the `shapes_graph_filename` respectively. The ontology graph is generated by the `load_ontology` method from tasty's `graphs` module (imported as `tg`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "african-installation",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...loaded data graph\n",
      "...loaded shapes graph\n",
      "...loaded ontology graph\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# Generate Graphs\n",
    "# ----------------------------------------\n",
    "\n",
    "# Data Graph\n",
    "data_graph = get_data_graph()\n",
    "print(\"...loaded data graph\")\n",
    "\n",
    "# Shapes Graph\n",
    "shapes_graph = get_shapes_graph()\n",
    "print(\"...loaded shapes graph\")\n",
    "\n",
    "# Ontology Graph\n",
    "ont_graph = tg.load_ontology(tc.HAYSTACK, tc.V3_9_10)\n",
    "print(\"...loaded ontology graph\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-doctrine",
   "metadata": {},
   "source": [
    "### Add Sample Equipment as Target Node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-terrain",
   "metadata": {},
   "source": [
    "First we add a triple to the shapes graph:\n",
    "- The **subject** is the SHACL equipment shape\n",
    "- The **predicate** is `sh:targetNode`\n",
    "- The **object** is the sample equipment\n",
    "\n",
    "This indicates that the sample shape should conform to the overall SHACL equipment shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "turkish-pressing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tadded 'urn:sample/NREL-Equip-Test' as target node to https://project-haystack.org/datashapes/nrel#NREL-VAV-Test-Shape\n"
     ]
    }
   ],
   "source": [
    "# add Instance Equipment as target node to SHACL Equipment Shape\n",
    "shapes_graph.add((shape_name, SH.targetNode, target_node))\n",
    "print(f\"\\tadded '{target_node}' as target node to {shape_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-mercury",
   "metadata": {},
   "source": [
    "Next we iterate over all *nodes* of the SHACL equipment shape using rdflidb's `triples()` function which supports basic triple pattern matching ([see documentation here](https://rdflib.readthedocs.io/en/stable/intro_to_graphs.html)). For each triple with a subject of the SHACL equipment shape and predicate of `sh:node`, we take the object (i.e. all of the functional group shapes which constitute the equipment shape) and add the sample equipment as a target node to these shapes. This is done so that the validation results will identify specific points that fail to validate, rather than simply functional group shapes.</br>\n",
    "So for each *node* (functional group shape) add a triple to the shapes graph:\n",
    "- The **subject** is the *node* (functional group shape)\n",
    "- The **predicate** is `sh:targetNode`\n",
    "- The **object** is the sample equipment\n",
    "\n",
    "Ultimately, this means we are indicating that the sample equipment should conform to each of these functional group shapes independently. Note that this is acceptable currently because there is no `maxCount` on the functional group shape's `equipRef` path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "adult-liquid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tadded 'urn:sample/NREL-Equip-Test' as target node to https://project-haystack.org/datashapes/nrel#TestFunctionalShape1\n",
      "\tadded 'urn:sample/NREL-Equip-Test' as target node to https://project-haystack.org/datashapes/nrel#TestFunctionalShape2\n"
     ]
    }
   ],
   "source": [
    "# add Instance Equipment as target node to SHACL Functional Groups Shapes\n",
    "for s1, p1, o1 in shapes_graph.triples((shape_name, SH.node, None)):\n",
    "    shapes_graph.add((o1, SH.targetNode, target_node))\n",
    "    print(f\"\\tadded '{target_node}' as target node to {o1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-conducting",
   "metadata": {},
   "source": [
    "# 3) Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-latest",
   "metadata": {},
   "source": [
    "## PySHACL Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "protective-jamaica",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conforms: True\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# Run pySCHACL Validation\n",
    "# ----------------------------------------\n",
    "result = validate(data_graph, shacl_graph=shapes_graph, ont_graph=ont_graph)\n",
    "conforms, results_graph, results = result\n",
    "\n",
    "print(f\"Conforms: {conforms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "artificial-macintosh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix sh: <http://www.w3.org/ns/shacl#> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "[] a sh:ValidationReport ;\n",
      "    sh:conforms true .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_graph(results_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-batman",
   "metadata": {},
   "source": [
    "## Determine Missing Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "searching-manitoba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Points Missing\n"
     ]
    }
   ],
   "source": [
    "missing_points = []\n",
    "\n",
    "# Find the Validation Results\n",
    "for subject, predicate, object in results_graph.triples((None, RDF.type, SH.ValidationResult)):\n",
    "#     print(f\"Subject:{subject}\\tPredicate:{predicate}\\tObject:{object}\")\n",
    "\n",
    "    # check if Validation result points to a BNode\n",
    "    for node in results_graph.objects(subject=subject, predicate=SH.sourceShape):\n",
    "#         print(f\"\\tNode:{node}\\t\\tIs BNode:{isinstance(node, BNode)}\")\n",
    "\n",
    "        if isinstance(node, BNode):\n",
    "            point = results_graph.value(subject=node, predicate=SH.qualifiedValueShape)\n",
    "            missing_points.append(point)\n",
    "\n",
    "if len(missing_points) <= 0:\n",
    "    print(\"No Points Missing\")\n",
    "else:\n",
    "    print(\"Missing Points:\")\n",
    "    for point in missing_points:\n",
    "        print(f\"\\t{point}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-truth",
   "metadata": {},
   "source": [
    "## Print pySHACL Graphs and Results to File (Optional) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brutal-interface",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...printed results\n",
      "...printed data graph\n",
      "...printed shapes graph\n",
      "...printed results graph\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# Print Output Files\n",
    "# ----------------------------------------\n",
    "# Print Results to File\n",
    "fn = os.path.join(output_directory, \"results.txt\")\n",
    "f = open(fn, \"w\")\n",
    "f.write(results)\n",
    "f.close()\n",
    "print(\"...printed results\")\n",
    "\n",
    "# Print Graphs to File(s)\n",
    "print_graph_to_file(data_graph, \"data_graph\")\n",
    "print(\"...printed data graph\")\n",
    "print_graph_to_file(shapes_graph, \"shapes_graph\")\n",
    "print(\"...printed shapes graph\")\n",
    "print_graph_to_file(results_graph, \"results_graph\")\n",
    "print(\"...printed results graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-delta",
   "metadata": {},
   "source": [
    "## 3b) Brick Validation (Optional)\n",
    "Brickscehma uses pyshacl for validation, so it gives us the same result. In this case, we just passed in the shapes graph directly, so this is not actually testing conformance against a and actual brick model or using the brick schema in any significant way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "informed-garbage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brick Validation - Conforms: True\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# Run BrickSchema Validation\n",
    "# ----------------------------------------\n",
    "\n",
    "from brickschema import Graph\n",
    "\n",
    "# Set Up Graphs\n",
    "dg = Graph()\n",
    "df = os.path.join(tasty_main_directory, data_graph_filename)\n",
    "dg.load_file(df)\n",
    "\n",
    "sg = Graph()\n",
    "sf = os.path.join(tasty_main_directory, shapes_graph_filename)\n",
    "sg.load_file(sf)\n",
    "\n",
    "valid, _, report = dg.validate(shape_graphs=[sg])\n",
    "print(f\"Brick Validation - Conforms: {valid}\")\n",
    "if not valid:\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-segment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
